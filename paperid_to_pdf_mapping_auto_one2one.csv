paperId,Title,pdf_filename,match_score,pdf_title_guess,used_ocr
7c22a6a07e89461178b794681c675b209332ee15,Error Feedback Fixes SignSGD and other Gradient Compression Schemes,karimireddy19a.pdf,100.0,Error Feedback Fixes SignSGD and other Gradient Compression Schemes,False
44b3b3bb40a9055eccdf86ea1702f6ae8b38934c,Decentralized Stochastic Optimization and Gossip Algorithms with Compressed Communication,koloskova19a.pdf,100.0,Decentralized Stochastic Optimization and Gossip Algorithms with Compressed Communication,False
a8f3dc53e321fbb2565f5925def4365b9f68d1af,Self-Attention Generative Adversarial Networks,zhang19d.pdf,100.0,Self-Attention Generative Adversarial Networks,False
a22ac183c8b37824e32cae970db170b861a13438,Learning diverse rankings with multi-armed bandits,Copy of 1390156.1390255.pdf,100.0,Learning Diverse Rankings with Multi-Armed Bandits,False
ae6e206c8c2994e04c3fdc5bd97d81fdd0f27493,"On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization",Copy of NIPS-2008-on-the-complexity-of-linear-prediction-risk-bounds-margin-bounds-and-regularization-Paper.pdf,100.0,"On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization",False
02c388d43f619146ef64babb4c848190e83add1b,Group lasso with overlap and graph lasso,1553374.1553431.pdf,100.0,Group Lasso with Overlap and Graph Lasso,False
1f4294d8e0b0c8559479fac569fc0ea91b4dc0bd,"Adversarial Examples Are Not Bugs, They Are Features",NeurIPS-2019-adversarial-examples-are-not-bugs-they-are-features-Paper.pdf,100.0,"Adversarial Examples are not Bugs, they are Features",False
449310e3538b08b43227d660227dfd2875c3c3c1,Neural Ordinary Differential Equations,NeurIPS-2018-neural-ordinary-differential-equations-Paper.pdf,100.0,Neural Ordinary Differential Equations,False
1e80f755bcbf10479afd2338cec05211fdbd325c,Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations,1553374.1553453.pdf,100.0,Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations,False
ceb3eff13951d80813103172355820bc9493f172,Learning with structured sparsity,Copy of 1553374.1553429.pdf,100.0,Learning with Structured Sparsity,False
cf40878c2de992b6be053f79d3e97d20307dba26,Multi-Label Prediction via Compressed Sensing,Copy of NIPS-2009-multi-label-prediction-via-compressed-sensing-Paper.pdf,100.0,Multi-Label Prediction via Compressed Sensing,False
0389a414c5d0ef50e06fe0c15f6102f374ce1b04,A dual coordinate descent method for large-scale linear SVM,1390156.1390208.pdf,100.0,A Dual Coordinate Descent Method for Large-scale Linear SVM,False
14558cb69319eed0d5bfc5648aafcd09d882f443,Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks,arora19a.pdf,100.0,Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks,False
ebd660b8df9d7f9cd044c63778c15c39cdd072ed,Guaranteed Rank Minimization via Singular Value Projection,Copy of NIPS-2010-guaranteed-rank-minimization-via-singular-value-projection-Paper.pdf,100.0,Guaranteed Rank Minimization via Singular Value Projection,False
00bbfde6af97ce5efcf86b3401d265d42a95603d,Feature hashing for large scale multitask learning,1553374.1553516.pdf,100.0,Feature Hashing for Large Scale Multitask Learning,False
4e07791ee0872401215f12aefde342bd843240cc,Nonparametric Latent Feature Models for Link Prediction,NIPS-2009-nonparametric-latent-feature-models-for-link-prediction-Paper.pdf,100.0,Nonparametric Latent Feature Models for Link Prediction,False
1e826f01d02a8d514b8a687932d228781243496e,An accelerated gradient method for trace norm minimization,1553374.1553434.pdf,100.0,An Accelerated Gradient Method for Trace Norm Minimization,False
2f041bde7e1968427b09ce428116b21152c7e715,Evaluation methods for topic models,1553374.1553515.pdf,100.0,Evaluation Methods for Topic Models,False
3137bc367c61c0e507a5e3c1f8caeb26f292d79f,Measuring Invariances in Deep Networks,NIPS-2009-measuring-invariances-in-deep-networks-Paper.pdf,100.0,Measuring Invariances in Deep Networks,False
d9f6ada77448664b71128bb19df15765336974a6,SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems,Copy of NeurIPS-2019-superglue-a-stickier-benchmark-for-general-purpose-language-understanding-systems-Paper.pdf,100.0,SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems,False
e5554c9d5fa92af69992d72ed1fdfbe953b03fb4,Rethinking LDA: Why Priors Matter,Copy of NIPS-2009-rethinking-lda-why-priors-matter-Paper (1).pdf,100.0,Rethinking LDA: Why Priors Matter,False
ccb1bafdae68c635cbd30d49fda7dbf88a3ce1b6,Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data,Copy of NeurIPS-2018-learning-overparameterized-neural-networks-via-stochastic-gradient-descent-on-structured-data-Paper.pdf,100.0,Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data,False
2eacb358ba2c06a8706a58ed60c3a6a06d38fec0,Local Gaussian Process Regression for Real Time Online Model Learning,NIPS-2008-local-gaussian-process-regression-for-real-time-online-model-learning-Paper.pdf,100.0,Local Gaussian Process Regression for Real Time Online Model Learning and Control,False
a9022d8ffb5e417458fba9a280f90c1b08cb6c73,Stronger generalization bounds for deep nets via a compression approach,Copy of arora18b.pdf,100.0,Stronger Generalization Bounds for Deep Nets via a Compression Approach,False
08d0ea90b53aba0008d25811268fe46562cfb38c,On the quantitative analysis of deep belief networks,1390156.1390266.pdf,100.0,On the Quantitative Analysis of Deep Belief Networks,False
0728914a1dba0417bf2847548aa15711f3f8d4e8,Multi-view clustering via canonical correlation analysis,1553374.1553391.pdf,100.0,Multi-View Clustering via Canonical Correlation Analysis,False
0228810a988f6b8f06337e14f564e2fd3f6e1056,The Recurrent Temporal Restricted Boltzmann Machine,NIPS-2008-the-recurrent-temporal-restricted-boltzmann-machine-Paper.pdf,100.0,The Recurrent Temporal Restricted Boltzmann Machine,False
03e7e8663c69e691be6b6403b1eb1bbf593d31f2,Gradient Descent Finds Global Minima of Deep Neural Networks,du19c.pdf,100.0,Gradient Descent Finds Global Minima of Deep Neural Networks,False
811df72e210e20de99719539505da54762a11c6d,Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor,haarnoja18b.pdf,100.0,Soft Actor-Critic:,False
3c8a456509e6c0805354bd40a35e3f2dbf8069b1,"PyTorch: An Imperative Style, High-Performance Deep Learning Library",NeurIPS-2019-pytorch-an-imperative-style-high-performance-deep-learning-library-Paper.pdf,100.0,"PyTorch: An Imperative Style, High-Performance Deep Learning Library",False
a9ba0f45b97b3c5c261efb52d5e33490b60cbe10,Translated Learning: Transfer Learning across Different Feature Spaces,Copy of NIPS-2008-translated-learning-transfer-learning-across-different-feature-spaces-Paper.pdf,100.0,Translated Learning: Transfer Learning across Different Feature Spaces,False
80196cdfcd0c6ce2953bf65a7f019971e2026386,IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,espeholt18a.pdf,100.0,IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,False
4b5744dd44a0026c6f386d5cb21b795499d5efb7,Generalization Bounds of Stochastic Gradient Descent for Wide and Deep Neural Networks,NeurIPS-2019-generalization-bounds-of-stochastic-gradient-descent-for-wide-and-deep-neural-networks-Paper.pdf,100.0,Generalization Bounds of Stochastic Gradient Descent for Wide and Deep Neural Networks,False
cf80cc34528273d8fbe17783efe802a6509e1562,Online dictionary learning for sparse coding,Copy of 1553374.1553463.pdf,100.0,Online Dictionary Learning for Sparse Coding,False
6e4fd9b4b2b673c981cda528d8039a221ad35225,NAS-Bench-101: Towards Reproducible Neural Architecture Search,ying19a.pdf,100.0,NAS-Bench-101: Towards Reproducible Neural Architecture Search,False
ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc,Cross-lingual Language Model Pretraining,Copy of NeurIPS-2019-cross-lingual-language-model-pretraining-Paper.pdf,100.0,Cross-lingual Language Model Pretraining,False
b3f1aa12dde233aaf543bb9ccb27213c494e0fd5,Unlabeled Data Improves Adversarial Robustness,Copy of NeurIPS-2019-unlabeled-data-improves-adversarial-robustness-Paper.pdf,100.0,Unlabeled Data Improves Adversarial Robustness,False
3263ff3c16220322a3989d4f8bde16a53d9b8d45,Online Metric Learning and Fast Similarity Search,NIPS-2008-online-metric-learning-and-fast-similarity-search-Paper.pdf,100.0,Online Metric Learning and Fast Similarity Search,False
413263b022ab9ba239a4dd7887d3eeaba0fca258,Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity,NIPS-2008-gaussian-process-factor-analysis-for-low-dimensional-single-trial-analysis-of-neural-population-activity-Paper.pdf,100.0,Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity,False
ad7129af0644dbcafa9aa2f111cb76526ea444a1,Defending Against Neural Fake News,Copy of NeurIPS-2019-defending-against-neural-fake-news-Paper.pdf,100.0,Defending Against Neural Fake News,False
42ec3db12a2e4628885451b13035c2e975220a25,A Convergence Theory for Deep Learning via Over-Parameterization,allen-zhu19a.pdf,100.0,A Convergence Theory for Deep Learning via Over-Parameterization,False
4debb99c0c63bfaa97dd433bc2828e4dac81c48b,Addressing Function Approximation Error in Actor-Critic Methods,fujimoto18a.pdf,100.0,Addressing Function Approximation Error in Actor-Critic Methods,False
aa5741c74b7fac10680c1cfbdd49d9ffb5751a68,Using Pre-Training Can Improve Model Robustness and Uncertainty,Copy of hendrycks19a.pdf,100.0,Using Pre-Training Can Improve Model Robustness and Uncertainty,False
c42816f497d663c681df20d48a6e66a5632600d8,MixMatch: A Holistic Approach to Semi-Supervised Learning,NeurIPS-2019-mixmatch-a-holistic-approach-to-semi-supervised-learning-Paper.pdf,100.0,MixMatch: A Holistic Approach to Semi-Supervised Learning,False
04541599accc47d8174f63345ce9c987ef21685b,Disentangling by Factorising,kim18b.pdf,100.0,Disentangling by Factorising,False
cd10a147c94ecba92c8a400aa0fd04f912b4900c,Exploring Large Feature Spaces with Hierarchical Multiple Kernel Learning,Copy of NIPS-2008-exploring-large-feature-spaces-with-hierarchical-multiple-kernel-learning-Paper.pdf,100.0,Exploring Large Feature Spaces with Hierarchical Multiple Kernel Learning,False
e337c5e4c23999c36f64bcb33ebe6b284e1bcbf1,Large-scale deep unsupervised learning using graphics processors,Copy of 1553374.1553486.pdf,100.0,Large-scale Deep Unsupervised Learning using Graphics Processors,False
b32de117302258dd29919435cd001a8bcdfee3b3,Replicated Softmax: an Undirected Topic Model,NIPS-2009-replicated-softmax-an-undirected-topic-model-Paper.pdf,100.0,Replicated Softmax: an Undirected Topic Model,False
daf8cd0f2c159d022477914bfacee9ff6da70c8b,Adversarial Training and Robustness for Multiple Perturbations,NeurIPS-2019-adversarial-training-and-robustness-for-multiple-perturbations-Paper.pdf,100.0,Adversarial Training and Robustness for Multiple Perturbations,False
d18b48f77eb5c517a6d2c1fa434d2952a1b0a825,Hierarchical Graph Representation Learning with Differentiable Pooling,NeurIPS-2018-hierarchical-graph-representation-learning-with-differentiable-pooling-Paper.pdf,100.0,Hierarchical Graph Representation Learning with Differentiable Pooling,False
651adaa058f821a890f2c5d1053d69eb481a8352,Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples,athalye18a.pdf,100.0,Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples,False
5ae20e0bdfddc1888148e0fcde88d937e96318d2,Learning structural SVMs with latent variables,1553374.1553523.pdf,100.0,Learning Structural SVMs with Latent Variables,False
611fe6e34df07ea1b2104899e49642b4531b53e9,"Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers",NeurIPS-2019-learning-and-generalization-in-overparameterized-neural-networks-going-beyond-two-layers-Paper.pdf,100.0,"Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers",False
73d6a26f407db77506959fdf3f7b853e44f3844a,Training restricted Boltzmann machines using approximations to the likelihood gradient,1390156.1390290.pdf,100.0,Training Restricted Boltzmann Machines using Approximations to the Likelihood Gradient,False
94be567c32ae76bdaadabd4975807a94181e39b3,How Does Batch Normalization Help Optimization?,NeurIPS-2018-how-does-batch-normalization-help-optimization-Paper.pdf,100.0,How Does Batch Normalization Help Optimization?,False
c92be891c5f8f0f60b6de206364f9a744612d1e8,Adversarial Training for Free!,Copy of NeurIPS-2019-adversarial-training-for-free-Paper.pdf,100.0,Adversarial Training for Free!,False
800683edc4b24f61c985c025bab02e34ebff293b,Nonrigid Structure from Motion in Trajectory Space,NIPS-2008-nonrigid-structure-from-motion-in-trajectory-space-Paper.pdf,100.0,Nonrigid Structure from Motion in Trajectory Space,False
e0c6abdbdecf04ffac65c440da77fb9d66bb474c,XLNet: Generalized Autoregressive Pretraining for Language Understanding,NeurIPS-2019-xlnet-generalized-autoregressive-pretraining-for-language-understanding-Paper.pdf,100.0,XLNet: Generalized Autoregressive Pretraining for Language Understanding,False
804fb9542f4f56e264dd2df57c255a9a2011c00f,Adversarially Robust Generalization Requires More Data,NeurIPS-2018-adversarially-robust-generalization-requires-more-data-Paper.pdf,100.0,Adversarially Robust Generalization Requires More Data,False
6c405d4b5dc41a86be05acd59c06ed19daf01d14,Theoretically Principled Trade-off between Robustness and Accuracy,zhang19p.pdf,100.0,Theoretically Principled Trade-off between Robustness and Accuracy,False
7e71eedb078181873a56f2adcfef9dddaeb95602,Simplifying Graph Convolutional Networks,wu19e.pdf,100.0,Simplifying Graph Convolutional Networks,False
5a2668bf420d8509a4dfa28e1cdcdac14c649975,3D Object Recognition with Deep Belief Nets,NIPS-2009-3d-object-recognition-with-deep-belief-nets-Paper.pdf,100.0,3D Object Recognition with Deep Belief Nets,False
988a378f640eb7fb681f977d6cb1e0c830c07b4c,Adversarial Examples Are a Natural Consequence of Test Error in Noise,gilmer19a.pdf,100.0,Adversarial Examples Are a Natural Consequence of Test Error in Noise,False
6b4ca249b3b28d3fee65f69714440c08d42cee64,Which Training Methods for GANs do actually Converge?,mescheder18a.pdf,100.0,Which Training Methods for GANs do actually Converge?,False
77e379fd57ea44638fc628623e383eccada82689,Kernel Methods for Deep Learning,NIPS-2009-kernel-methods-for-deep-learning-Paper.pdf,100.0,Kernel Methods for Deep Learning,False
7a84a692327534fd227fa1e07fcb3816b633c591,Neural Tangent Kernel: Convergence and Generalization in Neural Networks,NeurIPS-2018-neural-tangent-kernel-convergence-and-generalization-in-neural-networks-Paper.pdf,100.0,Neural Tangent Kernel: Convergence and Generalization in Neural Networks,False
64441c8396211b5e799b9ad5138dade15ff5cd0a,Grassmann discriminant analysis: a unifying view on subspace-based learning,1390156.1390204.pdf,100.0,Grassmann Discriminant Analysis: a Unifying View on Subspace-Based Learning,False
5262fe8369992259be27165ccd09d1d31c7a4def,Bayesian probabilistic matrix factorization using Markov chain Monte Carlo,1390156.1390267.pdf,100.0,Bayesian Probabilistic Matrix Factorization using Markov Chain Monte Carlo,False
4eeac07324e5b15bca90295c66b21c05726ea2bb,Learning Non-Linear Combinations of Kernels,NIPS-2009-learning-non-linear-combinations-of-kernels-Paper.pdf,100.0,Learning Non-Linear Combinations of Kernels,False
8de174ab5419b9d3127695405efd079808e956e8,Curriculum learning,1553374.1553380.pdf,100.0,Curriculum Learning,False
65a9c7b0800c86a196bc14e7621ff895cc6ab287,ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks,NeurIPS-2019-vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks-Paper.pdf,100.0,ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks,False
4c746fb88a4b141ec3bca06504e800bf392ce170,Listwise approach to learning to rank: theory and algorithm,1390156.1390306.pdf,100.0,Listwise Approach to Learning to Rank - Theory and Algorithm,False
9491bcc1e54b52bea617283f7f716cf009068bce,Clustered Multi-Task Learning: A Convex Formulation,NIPS-2008-clustered-multi-task-learning-a-convex-formulation-Paper.pdf,100.0,Clustered Multi-Task Learning: a Convex Formulation,False
843959ffdccf31c6694d135fad07425924f785b1,Extracting and composing robust features with denoising autoencoders,1390156.1390294.pdf,100.0,Extracting and Composing Robust Features with Denoising Autoencoders,False
99990944b8516536f4ff2e5af6d9ea1c5993c0bd,Domain Adaptation with Multiple Sources,NIPS-2008-domain-adaptation-with-multiple-sources-Paper.pdf,100.0,Domain Adaptation with Multiple Sources,False
a188d2ac0d10bdd4d4a04c92cdc76523e11c155c,Privacy-preserving logistic regression,NIPS-2008-privacy-preserving-logistic-regression-Paper.pdf,100.0,Privacy-preserving logistic regression,False
9f9fc406c76255fec51a6196ce167c0ff1d1efc0,Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent,NeurIPS-2019-wide-neural-networks-of-any-depth-evolve-as-linear-models-under-gradient-descent-Paper.pdf,100.0,Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent,False
b3f83e8416010e9c3a705a0b6390d268e5ddf5c0,Black-box Adversarial Attacks with Limited Queries and Information,Copy of ilyas18a.pdf,100.0,Black-box Adversarial Attacks with Limited Queries and Information,False
554fabcedec7ee5361661614c6b45dc5661a5f79,Efficient Large-Scale Distributed Training of Conditional Maximum Entropy Models,NIPS-2009-efficient-large-scale-distributed-training-of-conditional-maximum-entropy-models-Paper.pdf,98.71794871794872,Efﬁcient Large-Scale Distributed Training of Conditional Maximum Entropy Models,False
1c71771c701aadfd72c5866170a9f5d71464bb88,Unified Language Model Pre-training for Natural Language Understanding and Generation,NeurIPS-2019-unified-language-model-pre-training-for-natural-language-understanding-and-generation-Paper.pdf,98.64864864864865,Uniﬁed Language Model Pre-training for Natural Language Understanding and Generation,False
4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,tan19a.pdf,98.57142857142857,EfﬁcientNet: Rethinking Model Scaling for Convolutional Neural Networks,False
a53da9916b87fa295837617c16ef2ca6462cafb8,Classification using discriminative restricted Boltzmann machines,Copy of 1390156.1390224.pdf,98.4375,Classiﬁcation using Discriminative Restricted Boltzmann Machines,False
fe9b8aac9fa3bfd9724db5a881a578e471e612d7,Efficient Neural Architecture Search via Parameter Sharing,Copy of pham18a.pdf,98.24561403508773,Efﬁcient Neural Architecture Search via Parameter Sharing,False
f7f73185e3975bb62a3c42b2ba6bd4db57fee8ed,Certified Adversarial Robustness via Randomized Smoothing,Copy of cohen19c.pdf,98.21428571428571,Certiﬁed Adversarial Robustness via Randomized Smoothing,False
1029daa28aa772e441470e61bdd610c222e92932,On Exact Computation with an Infinitely Wide Neural Net,NeurIPS-2019-on-exact-computation-with-an-infinitely-wide-neural-net-Paper.pdf,98.14814814814815,On Exact Computation with an Inﬁnitely Wide Neural Net,False
21b786b3f870fc7fa247c143aa41de88b1fc6141,Glow: Generative Flow with Invertible 1x1 Convolutions,NeurIPS-2018-glow-generative-flow-with-invertible-1x1-convolutions-Paper.pdf,98.07692307692308,Glow: Generative Flow × with Invertible 1 1 Convolutions,False
39b7007e6f3dd0744833f292f07ed77973503bfd,Data-Efficient Hierarchical Reinforcement Learning,NeurIPS-2018-data-efficient-hierarchical-reinforcement-learning-Paper.pdf,97.91666666666667,Data-Efﬁcient Hierarchical Reinforcement Learning,False
4e0bb8c1c683b43357c5d5216f6b74ff2cb32434,Do ImageNet Classifiers Generalize to ImageNet?,recht19a.pdf,97.22222222222223,Do ImageNet Classiﬁers Generalize to ImageNet?,False
cc97aae9c1bc35e01a737aa4bf5fa4677505ec44,Deflation Methods for Sparse PCA,NIPS-2008-deflation-methods-for-sparse-pca-Paper.pdf,96.7741935483871,Deﬂation Methods for Sparse PCA,False
6400c36efdb8a66b401b6aef26c057227266fddd,PointCNN: Convolution On X-Transformed Points,NeurIPS-2018-pointcnn-convolution-on-x-transformed-points-Paper.pdf,96.55172413793103,PointCNN: Convolution On -Transformed Points X,False
7af09246bae1d2d9abada79f441ba25858c69ef9,Confidence-weighted linear classification,1390156.1390190.pdf,94.73684210526315,Conﬁdence-Weighted Linear Classiﬁcation,False
57458bc1cffe5caa45a885af986d70f723f406b4,A unified architecture for natural language processing:deep neural networks with multitask learning,1390156.1390177.pdf,94.35897435897436,A Uniﬁed Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning,False
f53936c03fb089cc159c551081124aae8a32ec1a,Isolating Sources of Disentanglement in Variational Autoencoders,NeurIPS-2018-isolating-sources-of-disentanglement-in-variational-autoencoders-Paper.pdf,93.97590361445783,Isolating Sources of Disentanglement in VAEs,False
ed7c7c079c8c54d3b82e016cc52a7a2c3a61f237,Efficient projections onto the l1-ball for learning in high dimensions,1390156.1390191.pdf,89.55223880597015,Efﬁcient Projections onto the -Ball for Learning in High Dimensions ℓ,False
